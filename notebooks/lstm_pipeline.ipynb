{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83793e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64884826",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r\"D:\\AI_PROJECTS\\Sentiment Analysis\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "LSTM_DIR = os.path.join(MODELS_DIR, \"lstm\")\n",
    "os.makedirs(LSTM_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d657c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"training.csv\"))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_DIR, \"validation.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63acd897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1 2 3 4 5]\n",
      "Num Classes: 6\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(MODELS_DIR, \"label_encoder.pkl\"), \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Labels:\", le.classes_)\n",
    "print(\"Num Classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7b1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"clean_train.csv\")\n",
    "valid_df = pd.read_csv(\"clean_valid.csv\")\n",
    "test_df  = pd.read_csv(\"clean_test.csv\")\n",
    "X_train_text = train_df[\"clean_text\"].astype(str).tolist()\n",
    "X_valid_text = valid_df[\"clean_text\"].astype(str).tolist()\n",
    "X_test_text  = test_df[\"clean_text\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "906ff2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_lstm = train_df[\"label_enc\"].values\n",
    "y_valid_lstm = valid_df[\"label_enc\"].values\n",
    "y_test_lstm  = test_df[\"label_enc\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e54c2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 120), (2000, 120), (2000, 120))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_WORDS = 50000\n",
    "MAX_LEN = 120\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "\n",
    "# Convert to sequences\n",
    "train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "valid_seq = tokenizer.texts_to_sequences(X_valid_text)\n",
    "test_seq  = tokenizer.texts_to_sequences(X_test_text)\n",
    "\n",
    "# Pad sequences\n",
    "X_train_lstm = pad_sequences(train_seq, maxlen=MAX_LEN, padding='post')\n",
    "X_valid_lstm = pad_sequences(valid_seq, maxlen=MAX_LEN, padding='post')\n",
    "X_test_lstm  = pad_sequences(test_seq, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "# Save tokenizer\n",
    "with open(os.path.join(LSTM_DIR, \"tokenizer.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "X_train_lstm.shape, X_valid_lstm.shape, X_test_lstm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a008dd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 120, 128)          6400000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              263168    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,680,006\n",
      "Trainable params: 6,680,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "\n",
    "    Bidirectional(LSTM(128, return_sequences=False)),\n",
    "\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b6a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 64s 961ms/step - loss: 1.5905 - accuracy: 0.3468 - val_loss: 1.4026 - val_accuracy: 0.5165\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 56s 895ms/step - loss: 1.0208 - accuracy: 0.6277 - val_loss: 0.7844 - val_accuracy: 0.7200\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 56s 885ms/step - loss: 0.5264 - accuracy: 0.8124 - val_loss: 0.5794 - val_accuracy: 0.8005\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 56s 890ms/step - loss: 0.2963 - accuracy: 0.9032 - val_loss: 0.4696 - val_accuracy: 0.8530\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 57s 903ms/step - loss: 0.1690 - accuracy: 0.9463 - val_loss: 0.4406 - val_accuracy: 0.8725\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 59s 937ms/step - loss: 0.1136 - accuracy: 0.9653 - val_loss: 0.4502 - val_accuracy: 0.8790\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 56s 889ms/step - loss: 0.0836 - accuracy: 0.9742 - val_loss: 0.4728 - val_accuracy: 0.8755\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 58s 925ms/step - loss: 0.0677 - accuracy: 0.9791 - val_loss: 0.4813 - val_accuracy: 0.8825\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    validation_data=(X_valid_lstm, y_valid_lstm),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219f4e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 28ms/step\n",
      "LSTM Valid Accuracy: 0.8725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       550\n",
      "           1       0.90      0.92      0.91       704\n",
      "           2       0.75      0.70      0.73       178\n",
      "           3       0.84      0.88      0.86       275\n",
      "           4       0.85      0.78      0.81       212\n",
      "           5       0.75      0.60      0.67        81\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.83      0.80      0.82      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "pred_valid_lstm = np.argmax(model.predict(X_valid_lstm), axis=1)\n",
    "\n",
    "print(\"LSTM Valid Accuracy:\", accuracy_score(y_valid_lstm, pred_valid_lstm))\n",
    "\n",
    "print(classification_report(\n",
    "    y_valid_lstm, \n",
    "    pred_valid_lstm, \n",
    "    target_names=[str(c) for c in le.classes_]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0364724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: D:\\AI_PROJECTS\\Sentiment Analysis\\models\\lstm\\lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(LSTM_DIR, \"lstm_model.h5\"))\n",
    "print(\"Model saved to:\", os.path.join(LSTM_DIR, \"lstm_model.h5\"))\n",
    "#!/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce9692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 29ms/step\n",
      "LSTM Test Accuracy: 0.8655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       581\n",
      "           1       0.89      0.92      0.90       695\n",
      "           2       0.68      0.68      0.68       159\n",
      "           3       0.83      0.87      0.85       275\n",
      "           4       0.88      0.79      0.83       224\n",
      "           5       0.60      0.50      0.55        66\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.80      0.78      0.79      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test_lstm = np.argmax(model.predict(X_test_lstm), axis=1)\n",
    "\n",
    "print(\"LSTM Test Accuracy:\", accuracy_score(y_test_lstm, pred_test_lstm))\n",
    "\n",
    "print(classification_report(\n",
    "    y_test_lstm, \n",
    "    pred_test_lstm, \n",
    "    target_names=[str(c) for c in le.classes_]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1aa05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_venv",
   "language": "python",
   "name": "sentiment_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

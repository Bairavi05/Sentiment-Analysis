{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b563ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in d:\\ai_projects\\sentiment analysis\\venv\\lib\\site-packages (3.1.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: joblib in d:\\ai_projects\\sentiment analysis\\venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in d:\\ai_projects\\sentiment analysis\\venv\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in d:\\ai_projects\\sentiment analysis\\venv\\lib\\site-packages (from xgboost) (1.15.3)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — install deps if needed (run once)\n",
    "!pip install xgboost joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acf9b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files expected:\n",
      "D:\\AI_PROJECTS\\Sentiment Analysis\\data\\training.csv\n",
      "D:\\AI_PROJECTS\\Sentiment Analysis\\data\\validation.csv\n",
      "D:\\AI_PROJECTS\\Sentiment Analysis\\data\\test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "BASE_DIR = r\"D:\\AI_PROJECTS\\Sentiment Analysis\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"training.csv\")\n",
    "VALID_PATH = os.path.join(DATA_DIR, \"validation.csv\")\n",
    "TEST_PATH  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "\n",
    "print(\"Files expected:\")\n",
    "print(TRAIN_PATH)\n",
    "print(VALID_PATH)\n",
    "print(TEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3a417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (16000, 2)\n",
      "Valid Shape: (2000, 2)\n",
      "Test Shape : (2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5362\n",
       "0    4666\n",
       "3    2159\n",
       "4    1937\n",
       "2    1304\n",
       "5     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "valid_df = pd.read_csv(VALID_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Train Shape:\", train_df.shape)\n",
    "print(\"Valid Shape:\", valid_df.shape)\n",
    "print(\"Test Shape :\", test_df.shape)\n",
    "\n",
    "train_df.head()\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caef803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0                            i didnt feel humiliated      0   \n",
       "1  i can go from feeling so hopeless to so damned...      0   \n",
       "2   im grabbing a minute to post i feel greedy wrong      3   \n",
       "3  i am ever feeling nostalgic about the fireplac...      2   \n",
       "4                               i am feeling grouchy      3   \n",
       "\n",
       "                                          clean_text  \n",
       "0                            i didnt feel humiliated  \n",
       "1  i can go from feeling so hopeless to so damned...  \n",
       "2   im grabbing a minute to post i feel greedy wrong  \n",
       "3  i am ever feeling nostalgic about the fireplac...  \n",
       "4                               i am feeling grouchy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 — simple text cleaning (customize as needed)\n",
    "import re\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    # remove urls, mentions, special chars\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s']\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to a small sample (for speed)\n",
    "train_df['clean_text'] = train_df['text'].astype(str).apply(clean_text)\n",
    "valid_df['clean_text'] = valid_df['text'].astype(str).apply(clean_text)\n",
    "test_df['clean_text']  = test_df['text'].astype(str).apply(clean_text)\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f177007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned datasets.\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataframes\n",
    "train_df.to_csv(\"clean_train.csv\", index=False)\n",
    "valid_df.to_csv(\"clean_valid.csv\", index=False)\n",
    "test_df.to_csv(\"clean_test.csv\", index=False)\n",
    "\n",
    "print(\"Saved cleaned datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e34d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — label encoding (train -> fit, apply to valid/test)\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df['label'].astype(str))\n",
    "y_valid = le.transform(valid_df['label'].astype(str))\n",
    "y_test  = le.transform(test_df['label'].astype(str))\n",
    "\n",
    "print(\"Classes (index -> label):\", dict(enumerate(le.classes_)))\n",
    "# save label encoder\n",
    "with open(os.path.join(MODELS_DIR, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(le, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ac1224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0                            i didnt feel humiliated      0   \n",
       "1  i can go from feeling so hopeless to so damned...      0   \n",
       "2   im grabbing a minute to post i feel greedy wrong      3   \n",
       "3  i am ever feeling nostalgic about the fireplac...      2   \n",
       "4                               i am feeling grouchy      3   \n",
       "\n",
       "                                          clean_text  label_enc  \n",
       "0                            i didnt feel humiliated          0  \n",
       "1  i can go from feeling so hopeless to so damned...          0  \n",
       "2   im grabbing a minute to post i feel greedy wrong          3  \n",
       "3  i am ever feeling nostalgic about the fireplac...          2  \n",
       "4                               i am feeling grouchy          3  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell X — Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit on training labels\n",
    "train_df['label_enc'] = le.fit_transform(train_df['label'])\n",
    "\n",
    "# Transform validation + test labels\n",
    "valid_df['label_enc'] = le.transform(valid_df['label'])\n",
    "test_df['label_enc']  = le.transform(test_df['label'])\n",
    "\n",
    "# Extract y values\n",
    "y_train = train_df['label_enc']\n",
    "y_valid = valid_df['label_enc']\n",
    "y_test  = test_df['label_enc']\n",
    "\n",
    "# Save encoder for future use\n",
    "with open(os.path.join(MODELS_DIR, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d5a854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shapes: (16000, 9115) (2000, 9115) (2000, 9115)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — TF-IDF (fit on train only)\n",
    "tfidf = TfidfVectorizer(max_features=50000, ngram_range=(1,3), stop_words='english',min_df=3)\n",
    "X_train = tfidf.fit_transform(train_df['clean_text'].tolist())\n",
    "X_valid = tfidf.transform(valid_df['clean_text'].tolist())\n",
    "X_test  = tfidf.transform(test_df['clean_text'].tolist())\n",
    "\n",
    "# save tfidf\n",
    "with open(os.path.join(MODELS_DIR, \"tfidf_vectorizer.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "print(\"TF-IDF shapes:\", X_train.shape, X_valid.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c43570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Decision Tree Parameters: {'min_samples_split': 2, 'min_samples_leaf': 8, 'max_depth': None, 'criterion': 'gini'}\n",
      "Decision Tree — valid acc: 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89       550\n",
      "           1       0.91      0.90      0.91       704\n",
      "           2       0.83      0.83      0.83       178\n",
      "           3       0.86      0.87      0.87       275\n",
      "           4       0.79      0.85      0.82       212\n",
      "           5       0.85      0.72      0.78        81\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.86      0.84      0.85      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "dt_params = {\n",
    "    \"max_depth\": [20, 40, 60, 80, 100, None],\n",
    "    \"min_samples_split\": [2, 4, 6, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 8],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_search = RandomizedSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_distributions=dt_params,\n",
    "    n_iter=20,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "dt_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Decision Tree Parameters:\", dt_search.best_params_)\n",
    "\n",
    "best_dt = dt_search.best_estimator_\n",
    "\n",
    "pred_valid_dt = best_dt.predict(X_valid)\n",
    "print(\"Decision Tree — valid acc:\", accuracy_score(y_valid, pred_valid_dt))\n",
    "print(classification_report(y_valid, pred_valid_dt,target_names=[str(c) for c in le.classes_]))\n",
    "\n",
    "with open(os.path.join(MODELS_DIR, \"decision_tree.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(best_dt, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10edb5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "Naive Bayes — valid acc: 0.8365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       550\n",
      "           1       0.82      0.93      0.87       704\n",
      "           2       0.87      0.58      0.70       178\n",
      "           3       0.89      0.79      0.83       275\n",
      "           4       0.82      0.75      0.79       212\n",
      "           5       0.83      0.49      0.62        81\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.85      0.74      0.78      2000\n",
      "weighted avg       0.84      0.84      0.83      2000\n",
      "\n",
      "\n",
      "Best NB Parameters: {'alpha': 0.1}\n",
      "Best CV Score: 0.8182498892120016\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 — Multinomial Naive Bayes training & evaluation\n",
    "nb_params = {\n",
    "    \"alpha\": [0.1, 0.3, 0.5, 0.7, 1.0, 2.0, 3.0]\n",
    "}\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_search = RandomizedSearchCV(\n",
    "    estimator=nb_model,\n",
    "    param_distributions=nb_params,\n",
    "    n_iter=7,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "nb_search.fit(X_train, y_train)\n",
    "\n",
    "pred_valid_nb = nb_search.predict(X_valid)\n",
    "print(\"Naive Bayes — valid acc:\", accuracy_score(y_valid, pred_valid_nb))\n",
    "print(classification_report(y_valid, pred_valid_nb, \n",
    "                            target_names=[str(c) for c in le.classes_]))\n",
    "\n",
    "print(\"\\nBest NB Parameters:\", nb_search.best_params_)\n",
    "print(\"Best CV Score:\", nb_search.best_score_)\n",
    "\n",
    "\n",
    "with open(os.path.join(MODELS_DIR, \"naive_bayes.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(nb_search, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca0f193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "XGBoost — valid acc: 0.909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       550\n",
      "           1       0.93      0.94      0.93       704\n",
      "           2       0.85      0.90      0.88       178\n",
      "           3       0.93      0.89      0.91       275\n",
      "           4       0.85      0.84      0.85       212\n",
      "           5       0.79      0.81      0.80        81\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.88      0.89      0.88      2000\n",
      "weighted avg       0.91      0.91      0.91      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 — XGBoost training & evaluation\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [200, 300, 500],\n",
    "    \"max_depth\": [4, 6, 8, 10],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\": [0, 1, 5]\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(le.classes_),\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=xgb_params,\n",
    "    n_iter=20,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "pred_valid_xgb = xgb_search.predict(X_valid)\n",
    "print(\"XGBoost — valid acc:\", accuracy_score(y_valid, pred_valid_xgb))\n",
    "print(classification_report(y_valid, pred_valid_xgb, \n",
    "                            target_names=[str(c) for c in le.classes_]))\n",
    "\n",
    "# Save\n",
    "with open(os.path.join(MODELS_DIR, \"xgboost.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(xgb_search, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1aae63ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Valid: 0.876\n",
      "NB Valid: 0.8365\n",
      "XGB Valid: 0.909\n"
     ]
    }
   ],
   "source": [
    "best_dt  = dt_search.best_estimator_\n",
    "best_nb  = nb_search.best_estimator_\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "\n",
    "# Predict\n",
    "pred_dt  = best_dt.predict(X_valid)\n",
    "pred_nb  = best_nb.predict(X_valid)\n",
    "pred_xgb = best_xgb.predict(X_valid)\n",
    "\n",
    "print(\"DT Valid:\", accuracy_score(y_valid, pred_dt))\n",
    "print(\"NB Valid:\", accuracy_score(y_valid, pred_nb))\n",
    "print(\"XGB Valid:\", accuracy_score(y_valid, pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a62ecfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running predictions for ensemble...\n",
      "Ensemble (majority vote) — valid acc: 0.902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       550\n",
      "           1       0.92      0.94      0.93       704\n",
      "           2       0.87      0.83      0.85       178\n",
      "           3       0.94      0.89      0.91       275\n",
      "           4       0.84      0.84      0.84       212\n",
      "           5       0.86      0.73      0.79        81\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.89      0.86      0.87      2000\n",
      "weighted avg       0.90      0.90      0.90      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 — Correct + Fast Ensemble (Majority Voting)\n",
    "from scipy.stats import mode\n",
    "\n",
    "print(\"\\nRunning predictions for ensemble...\")\n",
    "\n",
    "\n",
    "# Combine predictions → shape: (3, N)\n",
    "all_preds = np.vstack([pred_dt, pred_nb, pred_xgb])\n",
    "\n",
    "# Majority vote (axis=0 means column-wise vote)\n",
    "ensemble_preds, _ = mode(all_preds, axis=0)\n",
    "\n",
    "ensemble_preds = ensemble_preds.flatten()\n",
    "\n",
    "print(\"Ensemble (majority vote) — valid acc:\", accuracy_score(y_valid, ensemble_preds))\n",
    "\n",
    "print(classification_report(\n",
    "    y_valid, \n",
    "    ensemble_preds,\n",
    "    target_names=[str(c) for c in le.classes_]\n",
    "))\n",
    "\n",
    "# Saving nothing — ensemble is computed in app dynamically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7f65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_venv",
   "language": "python",
   "name": "sentiment_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
